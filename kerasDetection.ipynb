{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "kerasDetection.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xma8LHnHnQIV"
      },
      "source": [
        "####Analytics Vidya</b>\n",
        "###Face detection and counting</p></b>\n",
        "<p>People detection and head counting is one of the classical albeit challenging computer vision application. For this problem, given a group selfie/photo, you are required to count the number of heads present in the picture. You are provided with a training set of images with coordinates of bounding box and head count for each image and need to predict the headcount for each image in the test set.</p></br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pNqamX7xpIa_",
        "outputId": "3d37375b-19c7-4ae2-f311-29b64ec13c2e"
      },
      "source": [
        "from google.colab import drive\n",
        "import zipfile as zip1\n",
        "import os\n",
        "drive.mount('/content/drive')\n",
        "zip_ref = zip1.ZipFile('./drive/My Drive/Colab Notebooks/AnalyticsVidya/train_HNzkrPW (1).zip', 'r')\n",
        "zip_ref.extractall('train/')\n",
        "zip_ref.close()"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FazTJE_lnKGI",
        "outputId": "bc17fe49-45b5-467e-8be9-c4b18cf14576"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import pandas as pd\n",
        "\n",
        "IMG_SIZE = 128\n",
        "BATCH_SIZE = 128\n",
        "traindatagen = ImageDataGenerator(rescale=1./255)\n",
        "traincsv = pd.read_csv('train/train.csv',dtype={'Name': str,'HeadCount':int})\n",
        "trainFaceMaskcsv = pd.read_csv('train/bbox_train.csv',dtype={'Name': str,'width':float,'height':float,'xmin':float,'ymin':float,'xmax':float,'ymax':float})\n",
        "trainFaceMaskcsv['xmin'] = trainFaceMaskcsv['xmin']*IMG_SIZE/trainFaceMaskcsv['width']\n",
        "trainFaceMaskcsv['xmax'] = trainFaceMaskcsv['xmax']*IMG_SIZE/trainFaceMaskcsv['width']\n",
        "trainFaceMaskcsv['ymin'] = trainFaceMaskcsv['ymin']*IMG_SIZE/trainFaceMaskcsv['height']\n",
        "trainFaceMaskcsv['ymax'] = trainFaceMaskcsv['ymax']*IMG_SIZE/trainFaceMaskcsv['height']\n",
        "\n",
        "traingenerator = traindatagen.flow_from_dataframe(traincsv, directory='train/image_data/',x_col='Name', y_col=['Name','HeadCount'],target_size=(IMG_SIZE,IMG_SIZE), color_mode='rgb',class_mode='raw', batch_size=BATCH_SIZE,shuffle=False, seed=10)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 5733 validated image filenames.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4PQyY1SCPuK3"
      },
      "source": [
        "import numpy as np\n",
        "def get_iou(a, epsilon=1e-5):\n",
        "    a[:,9] = np.maximum(a[:,1], a[:,5])\n",
        "    a[:,10] = np.maximum(a[:,2], a[:,6])\n",
        "    a[:,11] = np.minimum(a[:,3], a[:,7])\n",
        "    a[:,12] = np.minimum(a[:,4], a[:,8])\n",
        "    overlap = np.multiply(np.maximum(0,np.subtract(a[:,11],a[:,9])),np.maximum(0,np.subtract(a[:,12],a[:,10])))\n",
        "    area_a = np.multiply(np.subtract(a[:,3],a[:,1]),np.subtract(a[:,4],a[:,2]))\n",
        "    area_b = np.multiply(np.subtract(a[:,7],a[:,5]),np.subtract(a[:,8],a[:,6]))\n",
        "    area_combined = np.subtract(area_a+area_b,overlap)+epsilon\n",
        "    a[:,13] = np.divide(overlap,area_combined)*IMG_SIZE\n",
        "    a[np.where(a[:,13] > 0),14] = IMG_SIZE \n",
        "    a[np.where(a[:,13] <= 0),14] = 0\n",
        "    return a"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3k37JcnB7jhO"
      },
      "source": [
        "def get_iou_tf(a, epsilon=1e-5):\r\n",
        "  a1max = tf.maximum(a[:,0], a[:,4])\r\n",
        "  a2max = tf.maximum(a[:,1], a[:,5])\r\n",
        "  a3min = tf.minimum(a[:,2], a[:,6])\r\n",
        "  a4min = tf.minimum(a[:,3], a[:,7])\r\n",
        "  overlap = tf.multiply(tf.maximum(0.0,tf.subtract(a3min,a1max)),tf.maximum(0.0,tf.subtract(a4min,a2max)))\r\n",
        "  area_a = tf.multiply(tf.subtract(a[:,2],a[:,0]),tf.subtract(a[:,3],a[:,1]))\r\n",
        "  area_b = tf.multiply(tf.subtract(a[:,6],a[:,4]),tf.subtract(a[:,7],a[:,5]))\r\n",
        "  area_combined = tf.add(tf.subtract(tf.add(area_a,area_b),overlap),epsilon)\r\n",
        "  return tf.divide(overlap,area_combined)"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hv-t6h2_hQ18"
      },
      "source": [
        "def getAnchorBasedSlidingWindow(image_size,anchor):\r\n",
        "  array = []\r\n",
        "  for i in range(0,image_size,anchor):\r\n",
        "    for j in range(0,image_size,anchor):\r\n",
        "      array.append([i,j,i+anchor,j+anchor])\r\n",
        "  return array\r\n",
        "\r\n",
        "def getallSlidingwindows(image_size):\r\n",
        "  window8 = np.array(getAnchorBasedSlidingWindow(image_size,8))\r\n",
        "  window16 = np.array(getAnchorBasedSlidingWindow(image_size,16))\r\n",
        "  window32 = np.array(getAnchorBasedSlidingWindow(image_size,32))\r\n",
        "  window64 = np.array(getAnchorBasedSlidingWindow(image_size,64))\r\n",
        "\r\n",
        "  return np.vstack([np.hstack([np.ones(shape=(window8.shape[0],1))*8,window8]),\r\n",
        "            np.hstack([np.ones(shape=(window16.shape[0],1))*16,window16]),\r\n",
        "            np.hstack([np.ones(shape=(window32.shape[0],1))*32,window32]),\r\n",
        "            np.hstack([np.ones(shape=(window64.shape[0],1))*64,window64])])"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z01lq3S-eA3d"
      },
      "source": [
        "def get_faceMasks(batch_y):\n",
        "  allwin = getallSlidingwindows(IMG_SIZE)\n",
        "  facemasks8 = np.zeros(shape=(batch_y.shape[0],int(IMG_SIZE/8),int(IMG_SIZE/8),7))\n",
        "  facemasks16 = np.zeros(shape=(batch_y.shape[0],int(IMG_SIZE/16),int(IMG_SIZE/16),7))\n",
        "  facemasks32 = np.zeros(shape=(batch_y.shape[0],int(IMG_SIZE/32),int(IMG_SIZE/32),7))\n",
        "  facemasks64 = np.zeros(shape=(batch_y.shape[0],int(IMG_SIZE/64),int(IMG_SIZE/64),7))\n",
        "  onestemp = np.ones(shape=(allwin.shape[0]),dtype=np.float64)\n",
        "  for i in range(batch_y.shape[0]):\n",
        "    faceList = trainFaceMaskcsv.where(trainFaceMaskcsv['Name']==batch_y[i][0])\n",
        "    faceList = faceList[faceList.Name.notnull()]\n",
        "    arr = []\n",
        "    for face in range(faceList['Name'].count()):\n",
        "      arr.append(np.concatenate([allwin,np.stack([onestemp*faceList['xmin'].iloc[face],onestemp*faceList['ymin'].iloc[face],onestemp*faceList['xmax'].iloc[face],onestemp*faceList['ymax'].iloc[face],\n",
        "                                   onestemp*0,onestemp*0,onestemp*0,onestemp*0,onestemp*0,onestemp*0,onestemp*faceList['Name'].count()],axis=1)],axis=1))\n",
        "    ious = get_iou(np.array(arr).reshape(faceList['Name'].count()*allwin.shape[0],16))\n",
        "    ious2 = pd.DataFrame(ious)\n",
        "    idx = ious2.loc[ious2.reset_index().groupby([0,1,2,3,4])[13].idxmax()]\n",
        "    idxarray = np.array(idx)\n",
        "    facemasks8[i] = np.reshape((idxarray[idxarray[:,0]==8][:,1:16]/IMG_SIZE)[:,[8,9,10,11,12,13,14]],newshape=(int(IMG_SIZE/8),int(IMG_SIZE/8),7))\n",
        "    facemasks16[i] = np.reshape((idxarray[idxarray[:,0]==16][:,1:16]/IMG_SIZE)[:,[8,9,10,11,12,13,14]],newshape=(int(IMG_SIZE/16),int(IMG_SIZE/16),7))\n",
        "    facemasks32[i] = np.reshape((idxarray[idxarray[:,0]==32][:,1:16]/IMG_SIZE)[:,[8,9,10,11,12,13,14]],newshape=(int(IMG_SIZE/32),int(IMG_SIZE/32),7))\n",
        "    facemasks64[i] = np.reshape((idxarray[idxarray[:,0]==64][:,1:16]/IMG_SIZE)[:,[8,9,10,11,12,13,14]],newshape=(int(IMG_SIZE/64),int(IMG_SIZE/64),7))\n",
        "  return [facemasks8.astype('float32'),facemasks16.astype('float32'),facemasks32.astype('float32'),facemasks64.astype('float32')]"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OmwLl4SObd8P"
      },
      "source": [
        "batch_x, batch_y = next(traingenerator)\r\n",
        "xx,[m1,m2,m3,m4] = batch_x,get_faceMasks(batch_y)"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "RrtqK0LsV5FU",
        "outputId": "ad623a46-8e4e-4377-b8d7-98ffb6ecfcf5"
      },
      "source": [
        "'''\r\n",
        "import tensorflow_addons as tfa\r\n",
        "bc1,bc2,mselabel,msepred,ioulabel,ioupred,classifylabel = reshape_things(m1[0:5], m1[10:15])\r\n",
        "bce = tfa.losses.GIoULoss(reduction=tf.keras.losses.Reduction.NONE)\r\n",
        "loss = bce(ioulabel,ioupred).numpy()\r\n",
        "#tf.nn.compute_average_loss(loss).numpy()\r\n",
        "loss\r\n",
        "'''"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nimport tensorflow_addons as tfa\\nbc1,bc2,mselabel,msepred,ioulabel,ioupred,classifylabel = reshape_things(m1[0:5], m1[10:15])\\nbce = tfa.losses.GIoULoss(reduction=tf.keras.losses.Reduction.NONE)\\nloss = bce(ioulabel,ioupred).numpy()\\n#tf.nn.compute_average_loss(loss).numpy()\\nloss\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LV4r9SJdrRXQ"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.python.keras.layers import (Flatten,LeakyReLU,AveragePooling2D,concatenate,\n",
        "                                            Reshape,Activation,Input, Conv2D, MaxPooling2D,\n",
        "                                            BatchNormalization, GlobalAveragePooling2D,SpatialDropout2D)\n",
        "def resNetBlock(input_image,num):\n",
        "\n",
        "  layer1 = Conv2D(128, 3, strides=(1,1), padding='same', use_bias=False,name ='rone'+str(num))(input_image)\n",
        "  layer1 = BatchNormalization()(layer1)\n",
        "  layer1 = SpatialDropout2D(0.25)(layer1)\n",
        "  layer1 = LeakyReLU(alpha=0.1)(layer1)\n",
        "  \n",
        "  layer3 = Conv2D(64, 1, strides=(1,1), padding='same', use_bias=False,name='rtwo'+str(num))(layer1)\n",
        "  layer3 = BatchNormalization()(layer3)\n",
        "  layer3 = SpatialDropout2D(0.25)(layer3)\n",
        "  layer3 = LeakyReLU(alpha=0.1)(layer3)\n",
        "    \n",
        "  return layer3  \n",
        "\n",
        "def build_model(img_size,img_ch):\n",
        "  input_sh = Input(shape=(img_size,img_size,img_ch)) \n",
        "\n",
        "  layer_1 = Conv2D(16, 3, strides=(1,1), padding='same', use_bias=False,name='one')(input_sh)\n",
        "  layer_1 = BatchNormalization()(layer_1)\n",
        "  layer_1 = SpatialDropout2D(0.25)(layer_1)\n",
        "  layer_1 = LeakyReLU(alpha=0.1)(layer_1)\n",
        "  \n",
        "  layer_2 = Conv2D(32, 3, strides=(1,1), padding='same', use_bias=False,name='two')(layer_1)\n",
        "  layer_2 = BatchNormalization()(layer_2)\n",
        "  layer_2 = SpatialDropout2D(0.25)(layer_2)\n",
        "  layer_2 = LeakyReLU(alpha=0.1)(layer_2)\n",
        "  \n",
        "  layer_3 = Conv2D(64, 3, strides=(1,1), padding='same', use_bias=False,name='three')(layer_2)\n",
        "  layer_3 = BatchNormalization()(layer_3)\n",
        "  layer_3 = SpatialDropout2D(0.25)(layer_3)\n",
        "  layer_3 = LeakyReLU(alpha=0.1)(layer_3)\n",
        " \n",
        "  resNetBlock1 = resNetBlock(layer_3,1)\n",
        "  concact1 = concatenate([resNetBlock1, layer_3])\n",
        "  layer_l = LeakyReLU(alpha=0.1)(concact1)\n",
        "  maxpool1 = MaxPooling2D(pool_size=(2, 2))(layer_l)\n",
        "\n",
        "  resNetBlock2 = resNetBlock(maxpool1,2)\n",
        "  outputy = Conv2D(8, 1, strides=(1,1), padding='same', use_bias=False,name='four')(resNetBlock2)\n",
        "  concact2 = concatenate([resNetBlock2, maxpool1])\n",
        "  layer_l2 = LeakyReLU(alpha=0.1)(concact2)\n",
        "  maxpool2 = MaxPooling2D(pool_size=(2, 2))(layer_l2)\n",
        "\n",
        "  resNetBlock3 = resNetBlock(maxpool2,3)\n",
        "  outputz = Conv2D(16, 1, strides=(1,1), padding='same', use_bias=False,name='five')(resNetBlock3)\n",
        "  concact3 = concatenate([resNetBlock3, maxpool2])\n",
        "  layer_l3 = LeakyReLU(alpha=0.1)(concact3)\n",
        "  maxpool3 = MaxPooling2D(pool_size=(2, 2))(layer_l3)\n",
        "  \n",
        "  resNetBlock4 = resNetBlock(maxpool3,4)\n",
        "  outputw = Conv2D(7, 1, strides=(1,1), padding='same', use_bias=False,name='six')(resNetBlock4)\n",
        "  concact4 = concatenate([resNetBlock4, maxpool3])\n",
        "  layer_l4 = LeakyReLU(alpha=0.1)(concact4)\n",
        "  maxpool4 = MaxPooling2D(pool_size=(2, 2))(layer_l4)\n",
        "  \n",
        "  resNetBlock5 = resNetBlock(maxpool4,5)\n",
        "  outputk = Conv2D(7, 1, strides=(1,1), padding='same', use_bias=False,name='seven')(resNetBlock5)\n",
        "  concact5 = concatenate([resNetBlock5, maxpool4])\n",
        "  layer_l5 = LeakyReLU(alpha=0.1)(concact5)\n",
        "  maxpool5 = MaxPooling2D(pool_size=(2, 2))(layer_l5)\n",
        "  \n",
        "  resNetBlock6 = resNetBlock(maxpool5,6)\n",
        "  concact6 = concatenate([resNetBlock6, maxpool5])\n",
        "  layer_l6 = LeakyReLU(alpha=0.1)(concact6)\n",
        "\n",
        "  layer_ant = Conv2D(7, (1,1), strides=(1,1), padding='same', use_bias=False, name='eight')(layer_l6)\n",
        "  layer_plus1 = Conv2D(7, (3,3), strides=(1,1),  use_bias=False, name='nine')(layer_ant)\n",
        "  layer_plus2 = Conv2D(7, (3,3), strides=(1,1),padding='same', use_bias=False, name='ten')(layer_plus1)\n",
        "  #layer_plus3 = Conv2D(6, (3,3), strides=(1,1),  use_bias=False, name='eleven')(layer_plus2)\n",
        "  #model = Model(input_sh,outputs=[outputw,outputk,layer_ant,layer_plus2,layer_plus3])\n",
        "  model = tf.keras.Model(input_sh,outputs=[outputw,outputk,layer_ant,layer_plus2])\n",
        "  \n",
        "  #model = tf.keras.Model(input_sh,outputs=outputk)\n",
        "  return model"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "id": "waqFrquVz3iI",
        "outputId": "6e58e350-76b9-472e-9d8c-49b59dbef6a4"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "'''\r\n",
        "test = tf.constant([[[[1,1,9,1],[2,2,2,2]],\r\n",
        "                     [[3,3,3,3],[4,4,4,4]]],\r\n",
        "                   [[[10,10,90,10],[20,20,20,20]],\r\n",
        "                    [[30,30,30,30],[40,40,40,40]]]])\r\n",
        "\r\n",
        "fty = tf.reshape(test,shape=(test.shape[0]*test.shape[1]*test.shape[2],test.shape[3]))\r\n",
        "masked_labels = tf.TensorArray(dtype=fty.dtype, size=8, element_shape=())\r\n",
        "for k in range(labelarry.shape[0]):\r\n",
        "  if (fty[k,2] > 10):\r\n",
        "    masked_labels.write(k,fty[k,2])\r\n",
        "  else:\r\n",
        "    masked_labels.write(k,0)\r\n",
        "#tesnorop = tf.reshape(masked_labels.concat(),shape=(8,1))\r\n",
        "print(masked_labels.concat())\r\n",
        "'''"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\ntest = tf.constant([[[[1,1,9,1],[2,2,2,2]],\\n                     [[3,3,3,3],[4,4,4,4]]],\\n                   [[[10,10,90,10],[20,20,20,20]],\\n                    [[30,30,30,30],[40,40,40,40]]]])\\n\\nfty = tf.reshape(test,shape=(test.shape[0]*test.shape[1]*test.shape[2],test.shape[3]))\\nmasked_labels = tf.TensorArray(dtype=fty.dtype, size=8, element_shape=())\\nfor k in range(labelarry.shape[0]):\\n  if (fty[k,2] > 10):\\n    masked_labels.write(k,fty[k,2])\\n  else:\\n    masked_labels.write(k,0)\\n#tesnorop = tf.reshape(masked_labels.concat(),shape=(8,1))\\nprint(masked_labels.concat())\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L-4bBS-fmrlq",
        "outputId": "4ae1295e-3a80-4929-de60-2006a1f6f90f"
      },
      "source": [
        "resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])\r\n",
        "tf.config.experimental_connect_to_cluster(resolver)\r\n",
        "tf.tpu.experimental.initialize_tpu_system(resolver)\r\n",
        "print(\"All devices: \", tf.config.list_logical_devices('TPU'))\r\n",
        "strategy = tf.distribute.TPUStrategy(resolver)"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.81.164.90:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.81.164.90:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.81.164.90:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.81.164.90:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "All devices:  [LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:7', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:6', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:5', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:4', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:3', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:0', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:1', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:2', device_type='TPU')]\n",
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8oJNqWYLrQ1I"
      },
      "source": [
        "GLOBAL_BATCH_SIZE = BATCH_SIZE * strategy.num_replicas_in_sync"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q9Ny9y1nm1tr"
      },
      "source": [
        "import tensorflow_addons as tfa\r\n",
        "with strategy.scope():\r\n",
        "  gl = tfa.losses.GIoULoss(reduction=tf.keras.losses.Reduction.NONE)\r\n",
        "  bce = tf.keras.losses.BinaryCrossentropy(reduction=tf.keras.losses.Reduction.NONE)\r\n",
        "  mse = tf.keras.losses.MeanSquaredError(reduction=tf.keras.losses.Reduction.NONE)\r\n",
        "  mseMetric = tf.keras.metrics.MeanSquaredError()\r\n",
        "  classifiMetric = tf.keras.metrics.BinaryCrossentropy()\r\n",
        "\r\n",
        "  def reshape_things(labels, predictions):\r\n",
        "    shape = (labels.shape[0]*labels.shape[1]*labels.shape[2],labels.shape[3])\r\n",
        "    labels_shaped = tf.reshape(labels,shape=shape)\r\n",
        "    predictions_shaped = tf.reshape(predictions,shape=shape)\r\n",
        "    classifylabel = tf.reshape(labels_shaped[:,5],shape=(labels_shaped[:,5].shape[0],1))\r\n",
        "    classifypred = tf.reshape(predictions_shaped[:,5],shape=(predictions_shaped[:,5].shape[0],1))\r\n",
        "    bc1 = tf.concat([classifylabel,tf.abs(tf.subtract(classifylabel,tf.ones(classifylabel.shape)))],axis=1)\r\n",
        "    bc2 = tf.concat([classifypred,tf.abs(tf.subtract(classifypred,tf.ones(classifypred.shape)))],axis=1)\r\n",
        "    mselabel = tf.reshape(labels_shaped[:,6],shape=(labels_shaped[:,6].shape[0],1))\r\n",
        "    msepred = tf.reshape(predictions_shaped[:,6],shape=(predictions_shaped[:,6].shape[0],1))\r\n",
        "    ioulabel = tf.reshape(labels_shaped[:,0:4],shape=(labels_shaped[:,0:4].shape[0],4))\r\n",
        "    ioupred = tf.reshape(predictions_shaped[:,0:4],shape=(predictions_shaped[:,0:4].shape[0],4))\r\n",
        "    return bc1,bc2,mselabel,msepred,ioulabel,ioupred,classifylabel\r\n",
        "  \r\n",
        "  def compute_loss(labels, predictions):\r\n",
        "    bc1,bc2,mselabel,msepred,ioulabel,ioupred,classifylabel = reshape_things(labels, predictions)\r\n",
        "    p1 = bce(bc1,bc2)\r\n",
        "    p2 = mse(mselabel,msepred)\r\n",
        "    p3 = gl(ioulabel,ioupred)\r\n",
        "    pp11 = tf.nn.compute_average_loss(p1, global_batch_size=GLOBAL_BATCH_SIZE)\r\n",
        "    pp22 = tf.nn.compute_average_loss(p2 *classifylabel, global_batch_size=GLOBAL_BATCH_SIZE)\r\n",
        "    pp33 = tf.nn.compute_average_loss(p3* classifylabel, global_batch_size=GLOBAL_BATCH_SIZE)\r\n",
        "    return pp11,pp22,pp33\r\n",
        "\r\n",
        "  def custom_metric(labels,predictions):\r\n",
        "    bc1,bc2,mselabel,msepred,ioulabel,ioupred,classifylabel = reshape_things(labels, predictions)\r\n",
        "    classifiMetric.update_state(bc1,bc2)\r\n",
        "    mseMetric.update_state(mselabel,msepred)\r\n",
        "    iou = get_iou_tf(tf.concat([ioulabel,ioupred],1))\r\n",
        "    return classifiMetric.result(),mseMetric.result(),tf.math.reduce_mean(iou)\r\n",
        "    \r\n",
        "  def custom_metric_reset():\r\n",
        "    return classifiMetric.reset_states(),mseMetric.reset_states()\r\n",
        "\r\n",
        "  model = build_model(IMG_SIZE,3)\r\n",
        "  optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tCrCd5Ky3j_l"
      },
      "source": [
        "from tensorflow.data import Dataset\r\n",
        "def train_step(input):\r\n",
        "  image,[label1,label2,label3,label4] = input\r\n",
        "  with tf.GradientTape() as tape:\r\n",
        "    predictions1,predictions2,predictions3,predictions4 = model(image, training=True)\r\n",
        "    c_loss1,mse_loss1,iou_loss1 = compute_loss(label1,predictions1)\r\n",
        "    c_loss2,mse_loss2,iou_loss2 = compute_loss(label2,predictions2)\r\n",
        "    c_loss3,mse_loss3,iou_loss3 = compute_loss(label3,predictions3)\r\n",
        "    c_loss4,mse_loss4,iou_loss4 = compute_loss(label4,predictions4)\r\n",
        "    loss_dict = {'op1_c_loss':c_loss1,'op1_mse_loss':mse_loss1,'op1_iou_loss':iou_loss1,\r\n",
        "                 'op2_c_loss':c_loss2,'op2_mse_loss':mse_loss2,'op2_iou_loss':iou_loss2,\r\n",
        "                 'op3_c_loss':c_loss3,'op3_mse_loss':mse_loss3,'op3_iou_loss':iou_loss3,\r\n",
        "                 'op4_c_loss':c_loss4,'op4_mse_loss':mse_loss4,'op4_iou_loss':iou_loss4}\r\n",
        "  gradients = tape.gradient(list(loss_dict.values()), model.trainable_variables)\r\n",
        "  updated_vars = optimizer.apply_gradients(list(zip(gradients,model.trainable_variables)))\r\n",
        "  clm1,mlm1,iou1 = custom_metric(label1,predictions1)\r\n",
        "  clm2,mlm2,iou2 = custom_metric(label2,predictions2)\r\n",
        "  clm3,mlm3,iou3 = custom_metric(label3,predictions3)\r\n",
        "  clm4,mlm4,iou4 = custom_metric(label4,predictions4)\r\n",
        "  metric_dict={'op1_c_metric':clm1,'op1_mse_metric':mlm1,'op1_iou_metric':iou1,\r\n",
        "                 'op2_c_metric':clm2,'op2_mse_metric':mlm2,'op2_iou_metric':iou2,\r\n",
        "                 'op3_c_metric':clm3,'op3_mse_metric':mlm3,'op3_iou_metric':iou3,\r\n",
        "                 'op4_c_metric':clm4,'op4_mse_metric':mlm4,'op4_iou_metric':iou4}\r\n",
        "  return loss_dict, metric_dict\r\n",
        "\r\n",
        "@tf.function\r\n",
        "def distributed_train_epoch(xx,yy):\r\n",
        "  [yy1,yy2,yy3,yy4] = yy\r\n",
        "  loss_dict,metric_dict = strategy.run(train_step,args=((xx,[yy1,yy2,yy3,yy4]),))\r\n",
        "  reduced_loss_dict = {}\r\n",
        "  reduced_metric_dict = {}\r\n",
        "  for key in loss_dict:\r\n",
        "    reduced_loss_dict[key] = strategy.reduce(tf.distribute.ReduceOp.SUM, loss_dict[key], axis=None)\r\n",
        "  for key in metric_dict:\r\n",
        "    reduced_metric_dict[key] = strategy.reduce(tf.distribute.ReduceOp.SUM, metric_dict[key], axis=None)\r\n",
        "  return reduced_loss_dict,reduced_metric_dict\r\n",
        "\r\n",
        "def custom_loop(initial_epoch,num_epochs):\r\n",
        "  for epoch in range(num_epochs):\r\n",
        "    total_loss=0.0\r\n",
        "    sum_loss_dict={'op1_c_loss':0.0,'op1_mse_loss':0.0,'op1_iou_loss':0.0,\r\n",
        "                 'op2_c_loss':0.0,'op2_mse_loss':0.0,'op2_iou_loss':0.0,\r\n",
        "                 'op3_c_loss':0.0,'op3_mse_loss':0.0,'op3_iou_loss':0.0,\r\n",
        "                 'op4_c_loss':0.0,'op4_mse_loss':0.0,'op4_iou_loss':0.0}\r\n",
        "    sum_metric_dict={'op1_c_metric':0.0,'op1_mse_metric':0.0,'op1_iou_metric':0.0,\r\n",
        "                 'op2_c_metric':0.0,'op2_mse_metric':0.0,'op2_iou_metric':0.0,\r\n",
        "                 'op3_c_metric':0.0,'op3_mse_metric':0.0,'op3_iou_metric':0.0,\r\n",
        "                 'op4_c_metric':0.0,'op4_mse_metric':0.0,'op4_iou_metric':0.0}\r\n",
        "    num_batches = 0\r\n",
        "    total_metric = 0.0\r\n",
        "    for batch in range(44):\r\n",
        "      num_batches +=1\r\n",
        "      batch_x, batch_y = next(traingenerator)\r\n",
        "      xx,[m1,m2,m3,m4] = batch_x,get_faceMasks(batch_y)\r\n",
        "      loss_dict, metric_dict = distributed_train_epoch(xx,[m1,m2,m3,m4])\r\n",
        "      total_metric += sum(metric_dict.values())\r\n",
        "      total_loss += sum(loss_dict.values())\r\n",
        "      for key in loss_dict:\r\n",
        "        sum_loss_dict[key] = sum_loss_dict[key] + loss_dict[key]\r\n",
        "        #print(key+\"   \"+str(loss_dict[key]))\r\n",
        "    total_metric = sum(metric_dict.values())/9\r\n",
        "    #for key in metric_dict:\r\n",
        "     # sum_metric_dict[key] = sum_metric_dict[key] + metric_dict[key]\r\n",
        "        #print(key+\"   \"+str(metric_dict[key]))\r\n",
        "      #custom_metric_reset()\r\n",
        "    custom_metric_reset()\r\n",
        "    template = ('Epoch: {}, Train Loss: {}, Train Accuracy: {}')\r\n",
        "    print(template.format(epoch,total_loss/num_batches,total_metric/num_batches))"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 637
        },
        "id": "slXJeRCMVXff",
        "outputId": "2399bfc2-1482-4e1b-ab94-43604db79e3e"
      },
      "source": [
        "custom_loop(0,20)"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-84-aea1047719b4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcustom_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-83-9ef18c6704c9>\u001b[0m in \u001b[0;36mcustom_loop\u001b[0;34m(initial_epoch, num_epochs)\u001b[0m\n\u001b[1;32m     57\u001b[0m       \u001b[0mbatch_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraingenerator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m       \u001b[0mxx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mm1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mm2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mm3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mm4\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mget_faceMasks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m       \u001b[0mloss_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdistributed_train_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mm1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mm2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mm3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mm4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m       \u001b[0mtotal_metric\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetric_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m       \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    869\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 871\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    872\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    724\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    725\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 726\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    727\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2967\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2968\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2969\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2970\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3360\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3204\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3205\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3206\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3207\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3208\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    975\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 977\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    978\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    <ipython-input-83-9ef18c6704c9>:33 distributed_train_epoch  *\n        loss_dict,metric_dict = strategy.run(train_step,args=((xx,[yy1,yy2,yy3,yy4]),))\n    <ipython-input-83-9ef18c6704c9>:19 train_step  *\n        updated_vars = optimizer.apply_gradients(list(zip(gradients,model.trainable_variables)))\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:598 apply_gradients  **\n        grads_and_vars = optimizer_utils.filter_empty_gradients(grads_and_vars)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/optimizer_v2/utils.py:79 filter_empty_gradients\n        ([v.name for _, v in grads_and_vars],))\n\n    ValueError: No gradients provided for any variable: ['one/kernel:0', 'batch_normalization_135/gamma:0', 'batch_normalization_135/beta:0', 'two/kernel:0', 'batch_normalization_136/gamma:0', 'batch_normalization_136/beta:0', 'three/kernel:0', 'batch_normalization_137/gamma:0', 'batch_normalization_137/beta:0', 'rone1/kernel:0', 'batch_normalization_138/gamma:0', 'batch_normalization_138/beta:0', 'rtwo1/kernel:0', 'batch_normalization_139/gamma:0', 'batch_normalization_139/beta:0', 'rone2/kernel:0', 'batch_normalization_140/gamma:0', 'batch_normalization_140/beta:0', 'rtwo2/kernel:0', 'batch_normalization_141/gamma:0', 'batch_normalization_141/beta:0', 'rone3/kernel:0', 'batch_normalization_142/gamma:0', 'batch_normalization_142/beta:0', 'rtwo3/kernel:0', 'batch_normalization_143/gamma:0', 'batch_normalization_143/beta:0', 'rone4/kernel:0', 'batch_normalization_144/gamma:0', 'batch_normalization_144/beta:0', 'rtwo4/kernel:0', 'batch_normalization_145/gamma:0', 'batch_normalization_145/beta:0', 'rone5/kernel:0', 'batch_normalization_146/gamma:0', 'batch_normalization_146/beta:0', 'rtwo5/kernel:0', 'batch_normalization_147/gamma:0', 'batch_normalization_147/beta:0', 'rone6/kernel:0', 'batch_normalization_148/gamma:0', 'batch_normalization_148/beta:0', 'rtwo6/kernel:0', 'batch_normalization_149/gamma:0', 'batch_normalization_149/beta:0', 'eight/kernel:0', 'nine/kernel:0', 'six/kernel:0', 'seven/kernel:0', 'ten/kernel:0'].\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u1B2dxjLgnBE"
      },
      "source": [
        "####Helper functions</b>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xykofu3AanLo"
      },
      "source": [
        "####Test Pre</b>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JuJ1rNHVQLCV"
      },
      "source": [
        "import tensorflow_addons as tfa\r\n",
        "import numpy\r\n",
        "class faceDetector(object):\r\n",
        "  def __init__(self, epochs, enable_function, model, batch_size, strategy):\r\n",
        "    self.epochs = epochs\r\n",
        "    self.batch_size = batch_size\r\n",
        "    self.enable_function = enable_function\r\n",
        "    self.strategy = strategy\r\n",
        "    #self.loss_object = loss_object\r\n",
        "    self.optimizer = tf.keras.optimizers.Adam()\r\n",
        "    self.train_acc_metric = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\r\n",
        "    #self.test_loss_metric = tf.keras.metrics.Sum(name='test_loss')\r\n",
        "    self.model = model\r\n",
        "\r\n",
        "  def train_step(self,input):\r\n",
        "    image,label = input\r\n",
        "    predictions = self.model(image, training=True)\r\n",
        "    p1 = tf.math.abs(tf.math.subtract(label[:,:,:,4],predictions[:,:,:,4]))\r\n",
        "    p2 = tf.math.abs(tf.math.subtract(label[:,:,:,5],predictions[:,:,:,5])) \r\n",
        "    return p1,p2\r\n",
        "\r\n",
        "  def distributed_train_epoch(self,generator,strategy):\r\n",
        "    total_loss = 0.0\r\n",
        "    num_train_batches = 0.0\r\n",
        "\r\n",
        "    def funkforgradient(image,label):\r\n",
        "      p1,p2 = strategy.run(self.train_step,args=((image,label),))\r\n",
        "      loop_loss1 = strategy.reduce(tf.distribute.ReduceOp.SUM, p1, axis=None)\r\n",
        "      loop_loss2 = strategy.reduce(tf.distribute.ReduceOp.SUM, p2, axis=None)\r\n",
        "      total_loss = tf.reduce_sum(loop_loss1)+tf.reduce_sum(loop_loss2)\r\n",
        "      return total_loss\r\n",
        "    \r\n",
        "    while True:\r\n",
        "      batch_x, batch_y = next(generator)\r\n",
        "      xx,yy = batch_x, get_faceMasks(batch_y,16)\r\n",
        "      with tf.GradientTape() as tape:\r\n",
        "        gradfunk = funkforgradient(xx,yy)\r\n",
        "      gradients = tape.gradient(gradfunk, self.model.trainable_variables)\r\n",
        "      updated_vars = self.optimizer.apply_gradients(zip(gradients,self.model.trainable_variables))\r\n",
        "      #total_loss1 += strategy.reduce(tf.distribute.ReduceOp.SUM, p1, axis=None)\r\n",
        "      #looploss = (tf.reduce_sum(p1)+tf.reduce_sum(p2))*(1./self.batch_size)\r\n",
        "      num_train_batches += 1\r\n",
        "    return train_loss, num_train_batches\r\n",
        "\r\n",
        "  def custom_loop(self, train_dist_dataset, strategy):\r\n",
        "    if self.enable_function:\r\n",
        "      distributed_train_epoch = tf.function(self.distributed_train_epoch)\r\n",
        "    for epoch in range(self.epochs):\r\n",
        "      #self.optimizer.learning_rate = self.decay(epoch)\r\n",
        "      train_total_loss, num_train_batches = distributed_train_epoch(train_dist_dataset,strategy)\r\n",
        "      template = ('Epoch: {}, Train Loss: {}, Train Accuracy: {}')\r\n",
        "      print(template.format(epoch,train_total_loss / num_train_batches,self.train_acc_metric.result()))\r\n",
        "      if epoch != self.epochs - 1:\r\n",
        "        self.train_acc_metric.reset_states()\r\n",
        "        self.test_acc_metric.reset_states()\r\n",
        "    return (train_total_loss / num_train_batches,self.train_acc_metric.result().numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "op7MIasIL-ea"
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "\n",
        "x_train,y_train = next(get_output(traingenerator))\n",
        "for pic in range(7):\n",
        "  im = np.array(x_train[pic*4])\n",
        "  fig,ax = plt.subplots(pic,figsize = (8, 8))\n",
        "  ax.imshow(im)\n",
        "  for anchor in range(len(y_train)):\n",
        "    boxes = np.reshape(y_train[30][anchor],newshape=(int((IMG_SIZE*IMG_SIZE)/(anchor_sizes[anchor]*anchor_sizes[anchor])),13))\n",
        "    boxes = boxes[boxes[:,12]>0]*IMG_SIZE\n",
        "    for box in range(len(boxes)):\n",
        "      ax.add_patch(patches.Rectangle((boxes[box,8],boxes[box,9]),boxes[box,10]-boxes[box,8],boxes[box,11]-boxes[box,9],linewidth=1,edgecolor='r',facecolor='none'))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HA-AC3XArEo7"
      },
      "source": [
        "from tensorflow.python.keras.callbacks import ModelCheckpoint\r\n",
        "import tensorflow_addons as tfa\r\n",
        "def learning_strategy(image_size,previous_epoch,epoch_size,batchsize,learning_rate):\r\n",
        "  \r\n",
        "  tf.keras.backend.clear_session()\r\n",
        "  resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])\r\n",
        "  tf.config.experimental_connect_to_cluster(resolver)\r\n",
        "  tf.tpu.experimental.initialize_tpu_system(resolver)\r\n",
        "  print(\"All devices: \", tf.config.list_logical_devices('TPU'))\r\n",
        "  strategy = tf.distribute.TPUStrategy(resolver)\r\n",
        "\r\n",
        "  with strategy.scope():\r\n",
        "    def my_loss5(y_true,y_pred):\r\n",
        "      loss_classification = tf.math.abs(tf.math.subtract(y_true[:,:,:,4],y_pred[:,:,:,4]))\r\n",
        "      loss_regression = tf.math.abs(tf.math.subtract(y_true[:,:,:,5],y_pred[:,:,:,5]))\r\n",
        "      gl = tfa.losses.GIoULoss()\r\n",
        "      loss = tf.keras.losses.Reduction.SUM(loss_classification)+tf.keras.losses.Reduction.SUM(loss_regression)+tf.keras.losses.Reduction.SUM(gl(y_true[:,:,:,0:4], y_pred[:,:,:,0:4]))\r\n",
        "      return loss\r\n",
        "    \r\n",
        "    modelx = build_model(image_size,3)\r\n",
        "  #current_model.compile(loss={'six':my_loss5,'seven':my_loss5,'eight':my_loss5,'ten':my_loss5,'eleven':my_loss5} ,optimizer='adam',metrics=['accuracy'])\r\n",
        "    #modelx.compile(loss={'six':loss,'seven':loss,'eight':loss,'ten':loss} ,optimizer='adam',metrics=['accuracy'])\r\n",
        "    modelx.compile(loss=my_loss5 ,optimizer='adam',metrics=['accuracy'])\r\n",
        "  \r\n",
        "    #checkpoint = ModelCheckpoint('drive/My Drive/Colab Notebooks/AnalyticsVidya/FaceDetection/Weights/face_detectionTPU.hdf5',monitor='ten_accuracy',\r\n",
        "     #                        save_weights_only=False,save_best_only = True,mode='auto')\r\n",
        "  #checkpoint = ModelCheckpoint('/gdrive/My Drive/tpuweights/vddddAssignment4Amodel_{epoch:02d}_{val_loss:.2f}.hdf5',monitor='val_acc',save_weights_only=True,save_best_only = True,mode='auto')\r\n",
        "    #modelx.fit(get_output(traingenerator),initial_epoch=previous_epoch,epochs=epoch_size,steps_per_epoch=int(5733/32),verbose=1,callbacks=[checkpoint])   \r\n",
        "    modelx.fit(get_output(traingenerator),initial_epoch=previous_epoch,epochs=epoch_size,steps_per_epoch=int(5733/32),verbose=1)                       "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yXIo_F7Oso6C"
      },
      "source": [
        "learning_strategy(128,0,20,32,0.001)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I-6S5rX4G3qQ"
      },
      "source": [
        "AUTO = tf.data.experimental.AUTOTUNE\r\n",
        "\r\n",
        "IMAGE_SIZE = [128, 128]\r\n",
        "\r\n",
        "batch_size = 16 * tpu_strategy.num_replicas_in_sync\r\n",
        "\r\n",
        "gcs_pattern = 'gs://faces/tfrecords-jpeg-128/*.tfrec'\r\n",
        "filenames = tf.io.gfile.glob(gcs_pattern)\r\n",
        "train_fns = filenames[:split]\r\n",
        "\r\n",
        "def parse_tfrecord(example):\r\n",
        "  features = {\r\n",
        "    \"image\": tf.io.FixedLenFeature([], tf.string), # tf.string means bytestring\r\n",
        "    \"class\": tf.io.FixedLenFeature([], tf.int64),  # shape [] means scalar\r\n",
        "    \"one_hot_class\": tf.io.VarLenFeature(tf.float32),\r\n",
        "  }\r\n",
        "  example = tf.io.parse_single_example(example, features)\r\n",
        "  decoded = tf.image.decode_jpeg(example['image'], channels=3)\r\n",
        "  normalized = tf.cast(decoded, tf.float32) / 255.0 # convert each 0-255 value to floats in [0, 1] range\r\n",
        "  image_tensor = tf.reshape(normalized, [*IMAGE_SIZE, 3])\r\n",
        "  one_hot_class = tf.reshape(tf.sparse.to_dense(example['one_hot_class']), [5])\r\n",
        "  return image_tensor, one_hot_class"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2U-pmFtXwBf9"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "def get_output(batch):\n",
        "  while True:\n",
        "    batch_x, batch_y = next(batch)\n",
        "    #batch_x_dataset = tf.data.Dataset.from_tensor_slices(batch_x)\n",
        "    #batch_y_dataset = tf.data.Dataset.from_tensor_slices(batch_y)\n",
        "    #yield (batch_x, [get_faceMasks(batch_y,8),get_faceMasks(batch_y,16),get_faceMasks(batch_y,32),get_faceMasks(batch_y,64)])\n",
        "    yield batch_x, get_faceMasks(batch_y,16)\n",
        "    #yield tf.data.Dataset.from_tensor_slices((batch_x_dataset, [get_faceMasks(batch_y_dataset,8),get_faceMasks(batch_y_dataset,16),get_faceMasks(batch_y_dataset,32),get_faceMasks(batch_y_dataset,64)]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HhQo5KNR0pup"
      },
      "source": [
        "from tensorflow.python.keras.callbacks import ModelCheckpoint\r\n",
        "checkpoint = ModelCheckpoint('drive/My Drive/Colab Notebooks/AnalyticsVidya/FaceDetection/Weights/face_detectionTPU.hdf5',monitor='ten_accuracy',\r\n",
        "                             save_weights_only=False,save_best_only = True,mode='auto')\r\n",
        "current_model.fit(get_output(traingenerator),epochs=50,verbose=1,steps_per_epoch=int(5733/32),callbacks=[checkpoint])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b8Aj5Q8iP7AW"
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "from PIL import Image,ImageOps,ImageFilter\n",
        "import matplotlib.patches as patches\n",
        "import random\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
        "profile_cascade = cv2.CascadeClassifier('haarcascade_profileface.xml')\n",
        "eye_cascade = cv2.CascadeClassifier('haarcascade_eye.xml')\n",
        "item_num = random.randint(0,(x_ou[0].shape[0])-1)\n",
        "#item_num = 24\n",
        "img = Image.fromarray((x_ou[0][item_num]).astype('uint8'),mode='RGB')\n",
        "print(item_num)\n",
        "\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(1,1,1)\n",
        "ticks = np.arange(0, 256, 32)\n",
        "\n",
        "ax.set_xticks(ticks)\n",
        "ax.set_yticks(ticks)\n",
        "ax.grid(b=True,color='black')\n",
        "gray = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2GRAY)\n",
        "\n",
        "faces = face_cascade.detectMultiScale(gray, 1.01, 10)\n",
        "for (x1,y1,w1,h1) in faces:\n",
        "    print('x1 '+str(x1)+' y1 '+str(y1)+' w1 '+str(w1)+' h1 '+str(h1))\n",
        "    img = cv2.rectangle(np.array(img),(x1,y1),(x1+w1,y1+h1),(255,0,0),2)\n",
        "    roi_color = img[y1:y1+h1, x1:x1+w1]\n",
        "\n",
        "profiles = profile_cascade.detectMultiScale(gray, 1.01, 10)\n",
        "for (x2,y2,w2,h2) in profiles:\n",
        "    print('x2 '+str(x2)+' y2 '+str(y2)+' w2 '+str(w2)+' h2 '+str(h2))\n",
        "    img = cv2.rectangle(np.array(img),(x2,y2),(x2+w2,y2+h2),(0,255,0),2)\n",
        "    roi_color = img[y2:y2+h2, x2:x2+w2]\n",
        "\n",
        "ax.imshow(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s6LHBS_gh7o5"
      },
      "source": [
        "####Model</b>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CUZE-tU83JTy"
      },
      "source": [
        "16 x 16 x 5 x 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6CnKGl6rOyAe"
      },
      "source": [
        "import requests\n",
        "from io import BytesIO\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "\n",
        "response = requests.get('https://www.bmw.co.uk/bmw-cars/explore-the-range/lifestyle/image-thumb__14913__480x270/3-series-1920x1080.jpeg?1539010591')\n",
        "img = Image.open(BytesIO(response.content))\n",
        "img2 = img.resize((32, 32), Image.NEAREST) \n",
        "img3 =np.expand_dims(img2, axis=0)\n",
        "print(img3.shape)\n",
        "p = current_model.predict(img3)\n",
        "print(p.shape)\n",
        "print(p[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9KQjeOFnM_ja"
      },
      "source": [
        "def fetch_model(input_size):\n",
        "  files = os.listdir('/drive/My Drive/Colab Notebooks/AnalyticsVidya/FaceDetection')\n",
        "\n",
        "  matchs = [s for s in files if SAVED_MODEL in s]\n",
        "  \n",
        "  least_val_loss = 1000.00\n",
        "  previous_model_file = ''\n",
        "  for m in matchs:\n",
        "      if float((m.split('_',2)[2]).split('.hdf5',1)[0]) < least_val_loss:\n",
        "        least_val_loss = float((m.split('_',2)[2]).split('.hdf5',1)[0])\n",
        "        previous_model_file = '/drive/My Drive/Colab Notebooks/AnalyticsVidya/FaceDetection' + m\n",
        "  if(least_val_loss < 1000.00):\n",
        "      print(\"Loading previous model with least val loss: \"+ str(previous_model_file))\n",
        "      current_model = build_model(img_size=input_size)\n",
        "      current_model.load_weights(previous_model_file)\n",
        "  else:\n",
        "      print(\"No previous model..   creating new Model\")\n",
        "      current_model = build_model(img_size=input_size)\n",
        "  \n",
        "  return current_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2G-LMat4WNQ6"
      },
      "source": [
        "from tensorflow.python.ops import clip_ops\r\n",
        "from tensorflow.python.framework import constant_op\r\n",
        "\r\n",
        "\r\n",
        "def _constant_to_tensor(x, dtype):\r\n",
        "    return constant_op.constant(x, dtype=dtype)\r\n",
        "\r\n",
        "\r\n",
        "with strategy.scope():\r\n",
        "\r\n",
        "    num_classes = len(CLASSES)\r\n",
        "    \r\n",
        "    # About why we set `reduction` to 'none', please check this tutorial\r\n",
        "    # https://www.tensorflow.org/tutorials/distribute/custom_training#define_the_loss_function\r\n",
        "    # In particular, read the paragraph\r\n",
        "    #     <<If using tf.keras.losses classes (as in the example below), the loss reduction needs to be explicitly specified to be one of NONE or SUM. AUTO and SUM_OVER_BATCH_SIZE are disallowed when used with tf.distribute.Strategy.>>\r\n",
        "    \r\n",
        "    loss_object = tf.keras.losses.CategoricalCrossentropy(from_logits=False, reduction='none', label_smoothing=0.1)\r\n",
        "\r\n",
        "    def loss_function(labels, prob_dists, sample_weights=None):\r\n",
        "\r\n",
        "        if not sample_weights:\r\n",
        "            sample_weights = 1.0\r\n",
        "\r\n",
        "        # While trained with BATCH_SIZE = 8 * strategy.num_replicas_in_sync, I got `nan` values.\r\n",
        "        # Since we pass probability distribution to `CategoricalCrossentropy` with `from_logits` = False,\r\n",
        "        # which has numerical unstability issue,\r\n",
        "        # we use the same trick in the source code to avoid such unstabiltiy.\r\n",
        "        epsilon_ = _constant_to_tensor(tf.keras.backend.epsilon(), prob_dists.dtype.base_dtype)\r\n",
        "        prob_dists = clip_ops.clip_by_value(prob_dists, epsilon_, 1 - epsilon_)\r\n",
        "        \r\n",
        "        labels = tf.keras.backend.one_hot(labels, num_classes)\r\n",
        "        \r\n",
        "        loss = loss_object(labels, prob_dists)\r\n",
        "        \r\n",
        "        # About why we use `tf.nn.compute_average_loss`, please check this tutorial\r\n",
        "        # https://www.tensorflow.org/tutorials/distribute/custom_training#define_the_loss_function\r\n",
        "        \r\n",
        "        loss = tf.nn.compute_average_loss(loss, global_batch_size=BATCH_SIZE)\r\n",
        "\r\n",
        "        return loss"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}